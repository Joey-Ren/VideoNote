<template>
  <div class="page">
    <h1 class="page-title">è§†é¢‘é—®ç­”</h1>
    <p class="page-desc">åŸºäºè§†é¢‘å†…å®¹çš„ AI æ™ºèƒ½é—®ç­”</p>

    <!-- è§†é¢‘è¾“å…¥ -->
    <div class="card input-section">
      <input
        v-model="videoUrl"
        class="input"
        placeholder="ç²˜è´´è§†é¢‘é“¾æ¥ï¼ŒAI å°†åŸºäºè§†é¢‘å†…å®¹å›ç­”ä½ çš„é—®é¢˜..."
      />
      <button
        class="btn-primary"
        style="margin-top: 12px"
        :disabled="!videoUrl || isPrepared || isPreparing"
        @click="handlePrepare"
      >
        {{ isPreparing ? 'é¢„å¤„ç†ä¸­...' : isPrepared ? 'âœ“ å·²å°±ç»ª' : 'é¢„å¤„ç†è§†é¢‘' }}
      </button>
    </div>

    <!-- å¯¹è¯åŒºåŸŸ -->
    <div class="card chat-section">
      <div class="chat-messages" ref="chatContainer">
        <div v-if="messages.length === 0" class="chat-empty">
          é¢„å¤„ç†è§†é¢‘åï¼Œåœ¨ä¸‹æ–¹è¾“å…¥ä½ çš„é—®é¢˜
        </div>
        <div
          v-for="(msg, i) in messages"
          :key="i"
          class="chat-message"
          :class="'chat-message--' + msg.role"
        >
          <div class="chat-bubble">
            {{ msg.content }}
            <button
              v-if="msg.role === 'assistant' && msg.content"
              class="voice-play-btn"
              :title="isSpeaking ? 'åœæ­¢æ’­æ”¾' : 'è¯­éŸ³æ’­æ”¾'"
              @click="toggleSpeak(msg.content)"
            >
              {{ isSpeaking ? 'â¹' : 'ğŸ”Š' }}
            </button>
          </div>
        </div>
      </div>
      <div class="chat-input">
        <input
          v-model="question"
          class="input"
          placeholder="è¾“å…¥ä½ çš„é—®é¢˜..."
          :disabled="!isPrepared"
          @keydown.enter="handleAsk"
        />
        <button
          class="voice-btn"
          :class="{ 'voice-btn--active': isListening }"
          :disabled="!isPrepared"
          :title="isListening ? 'åœæ­¢å½•éŸ³' : 'è¯­éŸ³è¾“å…¥'"
          @click="toggleVoice"
        >
          <span class="voice-icon">{{ isListening ? 'â¹' : 'ğŸ¤' }}</span>
          <span v-if="isListening" class="voice-pulse" />
        </button>
        <button
          class="btn-primary"
          :disabled="!question || !isPrepared"
          @click="handleAsk"
        >
          å‘é€
        </button>
      </div>
      <div v-if="voiceStatus" class="voice-status">{{ voiceStatus }}</div>
    </div>
  </div>
</template>

<script setup lang="ts">
import { ref, nextTick, onBeforeUnmount } from 'vue'
import { startTranscription, getTranscriptionResult } from '@/api'
import type { QAMessage } from '@/types'

const videoUrl = ref('')
const question = ref('')
const isPrepared = ref(false)
const isPreparing = ref(false)
const isAsking = ref(false)
const isListening = ref(false)
const isSpeaking = ref(false)
const voiceStatus = ref('')
const autoSpeak = ref(true)
const transcriptionContext = ref('')
const messages = ref<QAMessage[]>([])
const chatContainer = ref<HTMLElement>()

let recognition: SpeechRecognition | null = null
let speechUtterance: SpeechSynthesisUtterance | null = null

function scrollToBottom() {
  nextTick(() => {
    if (chatContainer.value) {
      chatContainer.value.scrollTop = chatContainer.value.scrollHeight
    }
  })
}

// ========== è¯­éŸ³è¾“å…¥ (STT) ==========

function initRecognition(): SpeechRecognition | null {
  const SpeechRecognition = window.SpeechRecognition || (window as any).webkitSpeechRecognition
  if (!SpeechRecognition) {
    voiceStatus.value = 'å½“å‰æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«ï¼Œè¯·ä½¿ç”¨ Chrome'
    return null
  }

  const r = new SpeechRecognition()
  r.lang = 'zh-CN'
  r.continuous = false
  r.interimResults = true

  r.onresult = (event: SpeechRecognitionEvent) => {
    let transcript = ''
    for (let i = event.resultIndex; i < event.results.length; i++) {
      transcript += event.results[i][0].transcript
    }
    question.value = transcript
    if (event.results[event.results.length - 1].isFinal) {
      voiceStatus.value = ''
      isListening.value = false
      if (question.value.trim()) {
        handleAsk()
      }
    }
  }

  r.onerror = (event: SpeechRecognitionErrorEvent) => {
    isListening.value = false
    if (event.error === 'no-speech') {
      voiceStatus.value = 'æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•'
    } else if (event.error === 'not-allowed') {
      voiceStatus.value = 'éº¦å…‹é£æƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸'
    } else {
      voiceStatus.value = `è¯†åˆ«å¤±è´¥: ${event.error}`
    }
    setTimeout(() => { voiceStatus.value = '' }, 3000)
  }

  r.onend = () => {
    isListening.value = false
  }

  return r
}

function toggleVoice() {
  if (isListening.value) {
    recognition?.stop()
    isListening.value = false
    voiceStatus.value = ''
    return
  }

  if (!recognition) {
    recognition = initRecognition()
  }
  if (!recognition) return

  voiceStatus.value = 'æ­£åœ¨è†å¬...'
  isListening.value = true
  recognition.start()
}

// ========== è¯­éŸ³æ’­æŠ¥ (TTS) ==========

function speak(text: string) {
  stopSpeak()
  speechUtterance = new SpeechSynthesisUtterance(text)
  speechUtterance.lang = 'zh-CN'
  speechUtterance.rate = 1.1
  speechUtterance.onstart = () => { isSpeaking.value = true }
  speechUtterance.onend = () => { isSpeaking.value = false }
  speechUtterance.onerror = () => { isSpeaking.value = false }
  speechSynthesis.speak(speechUtterance)
}

function stopSpeak() {
  speechSynthesis.cancel()
  isSpeaking.value = false
}

function toggleSpeak(text: string) {
  if (isSpeaking.value) {
    stopSpeak()
  } else {
    speak(text)
  }
}

// ========== é¢„å¤„ç† ==========

async function handlePrepare() {
  if (!videoUrl.value || isPreparing.value) return
  isPreparing.value = true

  try {
    const resp = await startTranscription(videoUrl.value)

    await new Promise<void>((resolve, reject) => {
      const es = new EventSource(`/api/transcribe/progress/${resp.task_id}`)
      es.onmessage = (event) => {
        const data = JSON.parse(event.data)
        if (data.status === 'completed') { es.close(); resolve() }
        if (data.status === 'error') { es.close(); reject(new Error(data.message)) }
      }
      es.onerror = () => { es.close(); reject(new Error('è¿æ¥ä¸­æ–­')) }
    })

    const result = await getTranscriptionResult(resp.task_id)
    transcriptionContext.value = result.text
    isPrepared.value = true
  } catch {
    messages.value.push({
      role: 'assistant',
      content: 'é¢„å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥è§†é¢‘é“¾æ¥åé‡è¯•ã€‚',
      timestamp: Date.now(),
    })
  } finally {
    isPreparing.value = false
  }
}

// ========== é—®ç­” ==========

async function handleAsk() {
  if (!question.value || isAsking.value) return
  const q = question.value
  question.value = ''
  isAsking.value = true

  messages.value.push({ role: 'user', content: q, timestamp: Date.now() })
  scrollToBottom()

  messages.value.push({ role: 'assistant', content: '', timestamp: Date.now() })
  const assistantIdx = messages.value.length - 1

  try {
    const resp = await fetch('/api/qa/ask', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        video_url: videoUrl.value,
        question: q,
        context: transcriptionContext.value,
      }),
    })

    if (!resp.ok) throw new Error(`HTTP ${resp.status}`)
    if (!resp.body) throw new Error('æ— å“åº”')

    const reader = resp.body.getReader()
    const decoder = new TextDecoder()

    while (true) {
      const { done, value } = await reader.read()
      if (done) break

      const text = decoder.decode(value)
      const lines = text.split('\n')
      for (const line of lines) {
        if (line.startsWith('data: ')) {
          try {
            const data = JSON.parse(line.slice(6))
            if (data.content) {
              messages.value[assistantIdx] = {
                ...messages.value[assistantIdx],
                content: messages.value[assistantIdx].content + data.content,
              }
              scrollToBottom()
            }
          } catch {
            // skip
          }
        }
      }
    }

    if (autoSpeak.value && messages.value[assistantIdx].content) {
      speak(messages.value[assistantIdx].content)
    }
  } catch {
    messages.value[assistantIdx] = {
      ...messages.value[assistantIdx],
      content: 'å›ç­”å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚',
    }
  } finally {
    isAsking.value = false
    scrollToBottom()
  }
}

onBeforeUnmount(() => {
  recognition?.stop()
  stopSpeak()
})
</script>

<style scoped lang="scss">
@use '@/assets/styles/variables' as *;

.input-section {
  margin-bottom: $spacing-lg;
}

.chat-section {
  display: flex;
  flex-direction: column;
  height: 500px;
}

.chat-messages {
  flex: 1;
  overflow-y: auto;
  padding: $spacing-md 0;
}

.chat-empty {
  text-align: center;
  color: $text-muted;
  padding: $spacing-2xl;
}

.chat-message {
  display: flex;
  margin-bottom: $spacing-md;

  &--user {
    justify-content: flex-end;
  }

  &--assistant {
    justify-content: flex-start;
  }
}

.chat-bubble {
  max-width: 70%;
  padding: $spacing-sm $spacing-md;
  border-radius: $radius-lg;
  line-height: 1.6;
  position: relative;

  .chat-message--user & {
    background: $accent-primary;
    color: white;
    border-bottom-right-radius: $spacing-xs;
  }

  .chat-message--assistant & {
    background: $bg-input;
    color: $text-primary;
    border-bottom-left-radius: $spacing-xs;
  }
}

.voice-play-btn {
  background: none;
  border: none;
  cursor: pointer;
  font-size: 14px;
  padding: 2px 4px;
  margin-left: 6px;
  opacity: 0.5;
  transition: opacity $transition-fast;
  vertical-align: middle;

  &:hover {
    opacity: 1;
  }
}

.chat-input {
  display: flex;
  gap: $spacing-md;
  padding-top: $spacing-md;
  border-top: 1px solid $border-color;
}

.voice-btn {
  display: flex;
  align-items: center;
  justify-content: center;
  width: 40px;
  min-width: 40px;
  height: 40px;
  border-radius: 50%;
  border: 1px solid $border-light;
  background: $bg-input;
  cursor: pointer;
  position: relative;
  transition: all $transition-fast;

  &:hover:not(:disabled) {
    border-color: $accent-primary;
    background: $bg-hover;
  }

  &:disabled {
    opacity: 0.4;
    cursor: not-allowed;
  }

  &--active {
    border-color: $error;
    background: rgba($error, 0.1);
    animation: voice-glow 1.5s ease-in-out infinite;
  }
}

.voice-icon {
  font-size: 18px;
  line-height: 1;
}

.voice-pulse {
  position: absolute;
  inset: -4px;
  border-radius: 50%;
  border: 2px solid $error;
  animation: voice-ripple 1.5s ease-out infinite;
  pointer-events: none;
}

.voice-status {
  padding-top: $spacing-sm;
  font-size: $font-size-xs;
  color: $text-muted;
  text-align: center;
}

@keyframes voice-glow {
  0%, 100% { box-shadow: 0 0 0 0 rgba($error, 0.3); }
  50% { box-shadow: 0 0 12px 4px rgba($error, 0.2); }
}

@keyframes voice-ripple {
  0% { transform: scale(1); opacity: 0.6; }
  100% { transform: scale(1.4); opacity: 0; }
}
</style>
